{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2111d3bf-04c1-46e7-8e74-8e5b0f593d33",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "Suppose you are starting a company that grows and sells wild mushrooms. \n",
    "- Since not all mushrooms are edible, you'd like to be able to tell whether a given mushroom is edible or poisonous based on it's physical attributes\n",
    "- You have some existing data that you can use for this task. \n",
    "\n",
    "Can you use the data to help you identify which mushrooms can be sold safely? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f68d2c-1f12-4b78-9ba0-586d2ae50674",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "You will start by loading the dataset for this task. The dataset you have collected is as follows:\n",
    "\n",
    "|                                                     | Cap Color | Stalk Shape | Solitary | Edible |\n",
    "|:---------------------------------------------------:|:---------:|:-----------:|:--------:|:------:|\n",
    "| <img src=\"images/0.png\" alt=\"drawing\" width=\"50\"/> |   Brown   |   Tapering  |    Yes   |    1   |\n",
    "| <img src=\"images/1.png\" alt=\"drawing\" width=\"50\"/> |   Brown   |  Enlarging  |    Yes   |    1   |\n",
    "| <img src=\"images/2.png\" alt=\"drawing\" width=\"50\"/> |   Brown   |  Enlarging  |    No    |    0   |\n",
    "| <img src=\"images/3.png\" alt=\"drawing\" width=\"50\"/> |   Brown   |  Enlarging  |    No    |    0   |\n",
    "| <img src=\"images/4.png\" alt=\"drawing\" width=\"50\"/> |   Brown   |   Tapering  |    Yes   |    1   |\n",
    "| <img src=\"images/5.png\" alt=\"drawing\" width=\"50\"/> |    Red    |   Tapering  |    Yes   |    0   |\n",
    "| <img src=\"images/6.png\" alt=\"drawing\" width=\"50\"/> |    Red    |  Enlarging  |    No    |    0   |\n",
    "| <img src=\"images/7.png\" alt=\"drawing\" width=\"50\"/> |   Brown   |  Enlarging  |    Yes   |    1   |\n",
    "| <img src=\"images/8.png\" alt=\"drawing\" width=\"50\"/> |    Red    |   Tapering  |    No    |    1   |\n",
    "| <img src=\"images/9.png\" alt=\"drawing\" width=\"50\"/> |   Brown   |  Enlarging  |    No    |    0   |\n",
    "\n",
    "\n",
    "-  You have 10 examples of mushrooms. For each example, you have\n",
    "    - Three features\n",
    "        - Cap Color (`Brown` or `Red`),\n",
    "        - Stalk Shape (`Tapering (as in \\/)` or `Enlarging (as in /\\)`), and\n",
    "        - Solitary (`Yes` or `No`)\n",
    "    - Label\n",
    "        - Edible (`1` indicating yes or `0` indicating poisonous)\n",
    "\n",
    "<a name=\"3.1\"></a>\n",
    "### One hot encoded dataset\n",
    "For ease of implementation, we have one-hot encoded the features (turned them into 0 or 1 valued features)\n",
    "\n",
    "|                                                    | Brown Cap | Tapering Stalk Shape | Solitary | Edible |\n",
    "|:--------------------------------------------------:|:---------:|:--------------------:|:--------:|:------:|\n",
    "| <img src=\"images/0.png\" alt=\"drawing\" width=\"50\"/> |     1     |           1          |     1    |    1   |\n",
    "| <img src=\"images/1.png\" alt=\"drawing\" width=\"50\"/> |     1     |           0          |     1    |    1   |\n",
    "| <img src=\"images/2.png\" alt=\"drawing\" width=\"50\"/> |     1     |           0          |     0    |    0   |\n",
    "| <img src=\"images/3.png\" alt=\"drawing\" width=\"50\"/> |     1     |           0          |     0    |    0   |\n",
    "| <img src=\"images/4.png\" alt=\"drawing\" width=\"50\"/> |     1     |           1          |     1    |    1   |\n",
    "| <img src=\"images/5.png\" alt=\"drawing\" width=\"50\"/> |     0     |           1          |     1    |    0   |\n",
    "| <img src=\"images/6.png\" alt=\"drawing\" width=\"50\"/> |     0     |           0          |     0    |    0   |\n",
    "| <img src=\"images/7.png\" alt=\"drawing\" width=\"50\"/> |     1     |           0          |     1    |    1   |\n",
    "| <img src=\"images/8.png\" alt=\"drawing\" width=\"50\"/> |     0     |           1          |     0    |    1   |\n",
    "| <img src=\"images/9.png\" alt=\"drawing\" width=\"50\"/> |     1     |           0          |     0    |    0   |\n",
    "\n",
    "\n",
    "Therefore,\n",
    "- `X_train` contains three features for each example \n",
    "    - Brown Color (A value of `1` indicates \"Brown\" cap color and `0` indicates \"Red\" cap color)\n",
    "    - Tapering Shape (A value of `1` indicates \"Tapering Stalk Shape\" and `0` indicates \"Enlarging\" stalk shape)\n",
    "    - Solitary  (A value of `1` indicates \"Yes\" and `0` indicates \"No\")\n",
    "\n",
    "- `y_train` is whether the mushroom is edible \n",
    "    - `y = 1` indicates edible\n",
    "    - `y = 0` indicates poisonous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00eafb0-c289-4726-8d8f-8779c67e7916",
   "metadata": {},
   "source": [
    "## Solution:\n",
    "\n",
    "### Step - 1: Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ea250e9-538c-4934-916c-0cf358e44673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd1e647-ee43-4d59-b154-4f571b290ec3",
   "metadata": {},
   "source": [
    "### Step - 2: Importing Dataset\n",
    "* Since dataset is small, we can take the data manually as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eb9c2a79-22d2-4ebc-90ab-6cd8e2e7ea5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array([\n",
    "    [1,1,1],[1,0,1],[1,0,0],[1,0,0],[1,1,1],[0,1,1],[0,0,0],[1,0,1],[0,1,0],[1,0,0]\n",
    "])\n",
    "y_train = np.array([1,1,0,0,1,0,0,1,1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002762f0-3985-4039-bbaa-3d826f285a8a",
   "metadata": {},
   "source": [
    "### Step - 3: View the samples and dimensions of variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1e84c0d3-1c61-4ddc-9fd5-b3479996df1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 elements of X_train: \n",
      " [[1 1 1]\n",
      " [1 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 1 1]]\n",
      "\n",
      "First 5 elements of y_train: \n",
      " [1 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"First 5 elements of X_train: \\n\", X_train[:5])\n",
    "print(\"\\nFirst 5 elements of y_train: \\n\", y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "220fa786-038f-4da4-b0e3-2eada5c360b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_train is:  (10, 3)\n",
      "The shape of y_train is:  (10,)\n",
      "m = Number of Training Examples:  10\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of X_train is: \", X_train.shape)\n",
    "print(\"The shape of y_train is: \", y_train.shape)\n",
    "print(\"m = Number of Training Examples: \", len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c6032f-01b5-4adb-a740-e0886fe72e22",
   "metadata": {},
   "source": [
    "### Step - 4: Decision Tree\n",
    "\n",
    "The steps for building a decision tree are as follows:\n",
    "- Start with all examples at the root node\n",
    "- Calculate information gain for splitting on all possible features, and pick the one with the highest information gain\n",
    "- Split dataset according to the selected feature, and create left and right branches of the tree\n",
    "- Keep repeating the splitting process until the stopping criteria are met"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fda39a3-c2e0-44a3-9d19-2ae30c8a40b1",
   "metadata": {},
   "source": [
    "### Step - 4.1: Calculate Entropy\n",
    "* The function takes in a numpy array (`y`) that indicates whether the examples in that node are edible (`1`) or poisonous(`0`)\n",
    "\n",
    "* The entropy is calculated as \n",
    "\n",
    "$$H(p_1) = -p_1 \\text{log}_2(p_1) - (1- p_1)\\text{log}_2(1- p_1)$$\n",
    "\n",
    "where $p_1 = $ fraction of examples that are edible (i.e, have value = `1` in `y`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "740334dc-214a-4d71-b30b-8083ebdd77b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_entropy(y):\n",
    "\n",
    "    entropy = 0.0\n",
    "\n",
    "    # edge case 1: if length of y is = 0 , entropy is also 0\n",
    "    if (len(y) == 0):\n",
    "        return entropy\n",
    "    \n",
    "    p_1 = np.count_nonzero(y == 1) / len(y)\n",
    "\n",
    "    # edge case 2: if p_1 = 0 or p_1 = 1, one terms becomes 0 * log2(0) which is undefined\n",
    "    if (p_1 != 0 and p_1 != 1):\n",
    "        entropy = -p_1 * np.log2(p_1) - (1 - p_1) * np.log2(1 - p_1)\n",
    "\n",
    "    return entropy\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b756c36b-52f4-4703-8b40-595ff4e651df",
   "metadata": {},
   "source": [
    "### Step 4.2: Split Dataset\n",
    "`split_dataset` function takes the data at a node and a feature to split on and splits it into left and right branches. \n",
    "\n",
    "- For example, say we're starting at the root node (so `node_indices = [0,1,2,3,4,5,6,7,8,9]`), and we chose to split on feature `0`, which is whether or not the example has a brown cap. \n",
    "    - The output of the function is then, `left_indices = [0,1,2,3,4,7,9]` (data points with brown cap) and `right_indices = [5,6,8]` (data points without a brown cap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2af44c2e-7ab9-469d-bc10-688f4f70115d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, node_indices, selected_feature):\n",
    "    \"\"\"\n",
    "    We need to split the training examples with index = node_indices at the current node\n",
    "    X = data matrix at a node, shape = 2d numpy array\n",
    "    node_indices (list): List containing the active indices. I.e, the samples being considered at this step.\n",
    "    selected_feature (int): Index of the feature to split on\n",
    "    \"\"\"\n",
    "    left_indices = []\n",
    "    right_indices = []\n",
    "\n",
    "    for i in node_indices:\n",
    "        # if the selected feature value at i_th training example is 1, keep it in left_indices, if 0 keep it in right_indices\n",
    "        if X[i, selected_feature] == 1:\n",
    "            left_indices.append(i)\n",
    "        else:\n",
    "            right_indices.append(i)\n",
    "            \n",
    "    return left_indices, right_indices       \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c276b2b5-9ab1-4683-92bd-d37f938ff357",
   "metadata": {},
   "source": [
    "### Testing `split_dataset` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "836bfc95-bd61-4434-b0a4-3319b39b4d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CASE 1:\n",
      "Left indices:  [0, 1, 4, 5, 7]\n",
      "Right indices:  [2, 3, 6, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "root_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "feature = 2 # based on this feature, split the current nodes data\n",
    "\n",
    "left_indices, right_indices = split_dataset(X_train, root_indices, feature)\n",
    "\n",
    "print(\"CASE 1:\")\n",
    "print(\"Left indices: \", left_indices)\n",
    "print(\"Right indices: \", right_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365304a6-a848-445d-a37b-0a57274a2375",
   "metadata": {},
   "source": [
    "### Step - 4.3: Calculate information gain\n",
    "\n",
    "$$\\text{Information Gain} = H(p_1^\\text{node})- (w^{\\text{left}}H(p_1^\\text{left}) + w^{\\text{right}}H(p_1^\\text{right}))$$\n",
    "\n",
    "where \n",
    "- $H(p_1^\\text{node})$ is entropy at the node \n",
    "- $H(p_1^\\text{left})$ and $H(p_1^\\text{right})$ are the entropies at the left and the right branches resulting from the split\n",
    "- $w^{\\text{left}}$ and $w^{\\text{right}}$ are the proportion of examples at the left and right branch, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cdfa583d-7ea7-4b74-9da1-0efb337046d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_information_gain (X, y, node_indices, selected_feature):\n",
    "    # split the dataset\n",
    "    left_indices, right_indices = split_dataset(X, node_indices, selected_feature)\n",
    "\n",
    "    # some useful variable\n",
    "    X_node, y_node = X[node_indices], y[node_indices]\n",
    "    X_left, y_left = X[left_indices], y[left_indices]\n",
    "    X_right, y_right = X[right_indices], y[right_indices]\n",
    "\n",
    "    # initializing the parameters\n",
    "    information_gain = 0.0\n",
    "\n",
    "    # Computing necessary entropy\n",
    "    entropy_node = compute_entropy(y_node)\n",
    "    entropy_left = compute_entropy(y_left)\n",
    "    entropy_right = compute_entropy(y_right)\n",
    "\n",
    "    # compute weights\n",
    "    w_left = len(X_left) / len(X_node)\n",
    "    w_right = len(X_right) / len(X_node)\n",
    "\n",
    "    # information gain\n",
    "    information_gain = entropy_node - (w_left * entropy_left + w_right * entropy_right)\n",
    "\n",
    "    return information_gain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95361c0a-4f1e-4576-8530-1a4b1fabe930",
   "metadata": {},
   "source": [
    "### Step 4.4: Get the best split\n",
    "* Calculate information gain by splitting based on all the features one by one\n",
    "* returns the feature that gives maximum information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73a30900-8bf6-42b2-9f24-bc81943c899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_split(X, y, node_indices):\n",
    "    # number of features\n",
    "    num_features = X.shape[1]\n",
    "\n",
    "    # We need to return the best features index\n",
    "    best_feature = -1\n",
    "\n",
    "    max_info_gain = 0.0\n",
    "\n",
    "    for i in range (num_features):\n",
    "        # Calculate information gain when splitting based on the ith features\n",
    "        information_gain = compute_information_gain(X, y, node_indices, i)\n",
    "\n",
    "        if information_gain > max_info_gain:\n",
    "            best_feature = i\n",
    "            max_info_gain = information_gain\n",
    "\n",
    "    return best_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89a416c-8241-48c9-ac37-b1e4e2f5ee57",
   "metadata": {},
   "source": [
    "### Step - 5: Building the tree\n",
    "Let's use the functions implemented above to generate a decision tree by successively picking the best feature to split on until we reach the stopping criteria (assume, maximum depth is 2 for now)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1261c6ca-40f0-4d9f-9930-491bdd2e17a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = []\n",
    "\n",
    "def build_tree_recursive (X, y, node_indices, max_depth, current_depth):\n",
    "    # base case\n",
    "    if (current_depth == max_depth):\n",
    "        return\n",
    "    # find the best feature to split the current nodes\n",
    "    best_feature = get_best_split(X, y, node_indices)\n",
    "\n",
    "    # split the dataset based on the best feature\n",
    "    left_indices, right_indices = split_dataset(X, node_indices, best_feature)\n",
    "\n",
    "    tree.append((left_indices, right_indices, best_feature))\n",
    "\n",
    "    # Continue splitting the left and right child, increment current depth by one\n",
    "    build_tree_recursive(X, y, left_indices, max_depth, current_depth + 1)\n",
    "    build_tree_recursive(X, y, right_indices, max_depth, current_depth + 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8e03864e-3834-46bb-a764-3a47fbfc1fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([0, 1, 4, 5, 7], [2, 3, 6, 8, 9], 2), ([0, 1, 4, 7], [5], 0), ([8], [2, 3, 6, 9], 1)]\n"
     ]
    }
   ],
   "source": [
    "# call the recursive function to build the trees\n",
    "# Initially root_indices contains all the indexes from 0 to m - 1\n",
    "build_tree_recursive(X_train, y_train, root_indices, max_depth = 2, current_depth = 0)\n",
    "\n",
    "print(tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
